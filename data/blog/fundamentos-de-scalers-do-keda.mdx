---
title: Fundamentos de Scalers do KEDA
date: '2024-10-27'
tags: ['kubernetes', 'keda', 'scaling']
draft: false
summary: KEDA √© um projeto de c√≥digo aberto projetado para estender o Kubernetes, capacitando os desenvolvedores a escalarem suas aplica√ß√µes de forma cont√≠nua em resposta a cargas de trabalho vari√°veis desencadeadas por eventos.
images: ['/static/images/keda-interoperability.png']
layout: PostLayout
---

## O que s√£o os scalers?

Os scalers do KEDA s√£o objetos que ajudam suas aplica√ß√µes a funcionarem sem problemas enquanto economizam recursos. Esses componentes inteligentes atuam como mecanismos de escalonamento autom√°tico orientados por eventos, reagindo a sinais externos e instruindo suas implanta√ß√µes a escalarem para cima ou para baixo conforme necess√°rio.

Pense neles como guardas vigilantes, constantemente monitorando o ambiente e acionando a√ß√µes de escalonamento com base em regras predefinidas. Vamos verificar como eles funcionam.

## O que os Scalers do KEDA Fazem?

Os scalers do KEDA oferecem v√°rias vantagens em compara√ß√£o com os autoscalers tradicionais. Em vez de depender de m√©tricas internas, o KEDA responde a eventos externos. Os scalers do KEDA oferecem uma abordagem mais responsiva e adapt√°vel a ambientes din√¢micos.

### Vantagens dos Scalers do KEDA

#### Reagem a eventos externos

Ao contr√°rio dos autoscalers tradicionais baseados em recursos, os scalers do KEDA dependem de "eventos" externos (pense neles como sinais de diferentes fontes) para acionar ajustes. Esses eventos podem vir de v√°rias fontes, como filas de mensagens, bancos de dados, sistemas de monitoramento ou at√© mesmo servi√ßos personalizados.

#### Conduzem o escalonamento din√¢mico

Com base nos dados dos eventos, os scalers do KEDA determinam a a√ß√£o de escalonamento apropriada. Isso pode envolver aumentar ou diminuir o n√∫mero de r√©plicas dentro da sua implanta√ß√£o, ajustar os limites de recursos dos cont√™ineres ou at√© mesmo pausar implanta√ß√µes quando a demanda diminui.

#### Oferecem estrat√©gias de escalonamento personaliz√°veis

Voc√™ tem controle total sobre como suas aplica√ß√µes respondem aos eventos. Os scalers do KEDA permitem que voc√™ defina limites, regras de escalonamento e at√© mesmo janelas de tempo para acionar a√ß√µes, garantindo respostas precisas e adapt√°veis.

### Exemplos de Scalers do KEDA em A√ß√£o

- **Escalonamento de um servidor web com base no tr√°fego HTTP**: Imagine um scaler do KEDA monitorando as solicita√ß√µes HTTP recebidas. Quando o tr√°fego aumenta, o scaler aumenta automaticamente o n√∫mero de r√©plicas do servidor para lidar com a carga.
- **Processamento de um backlog de jobs com KEDA e Kafka**: Um scaler conectado a uma fila Kafka pode acionar o escalonamento de uma aplica√ß√£o de trabalho com base no n√∫mero de mensagens pendentes, garantindo um processamento eficiente dos jobs.
- **Ajuste de recursos do banco de dados com base na carga de consultas**: Um scaler do KEDA monitorando m√©tricas do banco de dados pode alocar dinamicamente recursos para sua inst√¢ncia de banco de dados √† medida que o volume de consultas aumenta, prevenindo a degrada√ß√£o do desempenho.

## Explorando Scalers Populares do KEDA

At√© abril de 2024, existiam mais de 60 scalers no ecossistema KEDA, incluindo op√ß√µes integradas e externas.

Os seguintes scalers est√£o entre os mais comumente usados, gra√ßas √† sua capacidade de trabalhar com plataformas e servi√ßos amplamente adotados em v√°rios ambientes, proporcionando op√ß√µes de escalonamento flex√≠veis e din√¢micas para implanta√ß√µes Kubernetes.

### Scalers Populares do KEDA

| Scaler                    | Descri√ß√£o                                                                                      |
| ------------------------- | ---------------------------------------------------------------------------------------------- |
| **HTTP Scaler**           | Escala com base no n√∫mero de conex√µes HTTP ativas.                                             |
| **Azure Queue Scaler**    | Escala com base no comprimento de uma fila do Azure.                                           |
| **Kafka Scaler**          | Escala com base em m√©tricas de t√≥picos Kafka, como atraso ou n√∫mero de mensagens em um t√≥pico. |
| **RabbitMQ Scaler**       | Escala com base no n√∫mero de mensagens em uma fila RabbitMQ.                                   |
| **AWS CloudWatch Scaler** | Escala com base em m√©tricas do AWS CloudWatch.                                                 |
| **Prometheus Scaler**     | Escala com base em uma consulta a um servidor Prometheus.                                      |
| **MySQL Scaler**          | Escala com base em uma consulta a um banco de dados MySQL.                                     |
| **Cron Scaler**           | Escala com base em uma programa√ß√£o Cron, √∫til para escalonamento baseado em tempo.             |

Cada scaler √© implementado como um recurso personalizado no Kubernetes, e voc√™ o define em seus arquivos de manifesto do Kubernetes (YAML). Por exemplo, se voc√™ quiser escalar uma implanta√ß√£o com base no comprimento de uma fila do Azure Service Bus, voc√™ definiria um `ScaledObject` em seu arquivo YAML do Kubernetes que referencia o scaler do Azure Service Bus. Esse scaler ent√£o monitoraria a fila e ajustaria o n√∫mero de pods em sua implanta√ß√£o com base no n√∫mero de mensagens na fila.

A flexibilidade do KEDA reside em sua capacidade de se integrar com uma ampla variedade de fontes de eventos e m√©tricas, tornando-o uma ferramenta vers√°til para escalonamento autom√°tico no Kubernetes. Isso permite que desenvolvedores e equipes de opera√ß√µes garantam que as aplica√ß√µes sejam escaladas precisamente de acordo com a demanda, otimizando o uso de recursos e custos.

## Melhores Pr√°ticas do KEDA

Para aproveitar ao m√°ximo as capacidades do KEDA, √© recomend√°vel seguir um conjunto de melhores pr√°ticas. Essas recomenda√ß√µes ajudam a otimizar o escalonamento autom√°tico em seu ambiente de nuvem, aumentando a efic√°cia do KEDA.

### Melhores Pr√°ticas no Uso do KEDA

| Pr√°tica                                           | Descri√ß√£o                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| ------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Compreenda a Fonte de Eventos**                 | Conhecimento Profundo da Integra√ß√£o: Tenha um entendimento completo da fonte de eventos (por exemplo, fila de mensagens, banco de dados, etc.) que aciona o escalonamento. Esse conhecimento ajuda a configurar corretamente o KEDA para responder √†s m√©tricas ou eventos certos. Sele√ß√£o Apropriada de M√©tricas: Escolha m√©tricas que reflitam com precis√£o a carga e a necessidade de escalonamento. Por exemplo, em uma fila de mensagens, o n√∫mero de mensagens pode ser uma m√©trica mais relevante do que a idade da mensagem mais antiga.                                                           |
| **Teste de Escalabilidade**                       | Teste de Desempenho: Antes de implantar em produ√ß√£o, teste como sua aplica√ß√£o escala sob diferentes cargas. Isso ajuda a ajustar os par√¢metros de escalonamento. Simule Eventos: Use ferramentas para simular a carga da fonte de eventos para entender como o KEDA reagir√° em v√°rios cen√°rios.                                                                                                                                                                                                                                                                                                           |
| **Otimize os Par√¢metros de Escalamento**          | Per√≠odos de Resfriamento: Configure per√≠odos de resfriamento apropriados para evitar a√ß√µes de escalonamento muito frequentes que podem levar √† instabilidade do sistema. Limites e Limiares: Defina limites e limiares razo√°veis para o escalonamento para evitar o superescalonamento, que pode levar ao esgotamento de recursos, e o subescalonamento, que pode afetar o desempenho.                                                                                                                                                                                                                    |
| **Gerenciamento Eficaz de Recursos**              | Solicita√ß√µes e Limites de Recursos: Defina solicita√ß√µes e limites de recursos do Kubernetes para seus Pods para garantir que o processo de escalonamento autom√°tico respeite a disponibilidade de recursos no cluster. Configura√ß√µes do HPA: Se estiver usando o KEDA com HPA, certifique-se de que as configura√ß√µes do HPA estejam alinhadas com os requisitos de desempenho e disponibilidade da sua aplica√ß√£o.                                                                                                                                                                                         |
| **Considera√ß√µes de Seguran√ßa**                    | Acesso Seguro √†s Fontes de Eventos: Garanta acesso seguro √†s suas fontes de eventos. Use controle de acesso baseado em fun√ß√µes (RBAC) e gerenciamento de segredos para credenciais. Auditoria e Monitoramento: Audite e monitore regularmente o acesso √†s fontes de eventos e as atividades de escalonamento para poss√≠veis problemas de seguran√ßa.                                                                                                                                                                                                                                                       |
| **Use M√©tricas Personalizadas Quando Apropriado** | Use Scalers Personalizados: Pode haver situa√ß√µes em que os scalers predefinidos n√£o se alinham totalmente com seus requisitos espec√≠ficos. Isso pode ser devido a l√≥gica de neg√≥cios √∫nica, fontes de eventos personalizadas ou m√©tricas espec√≠ficas que s√£o cr√≠ticas para o desempenho e escalabilidade da sua aplica√ß√£o, mas n√£o s√£o cobertas pelas op√ß√µes integradas do KEDA.                                                                                                                                                                                                                          |
| **Monitoramento e Observabilidade**               | Coleta de M√©tricas: Colete m√©tricas para o processo de escalonamento autom√°tico e a fonte de eventos para entender o comportamento de escalonamento ao longo do tempo. Logging: Habilite logs detalhados para solu√ß√£o de problemas e obten√ß√£o de insights sobre o processo de escalonamento.                                                                                                                                                                                                                                                                                                              |
| **Mantenha os Componentes do KEDA Atualizados**   | Melhorias de Desempenho: Atualize regularmente o KEDA para se beneficiar dos recursos mais recentes, corre√ß√µes de bugs e patches de seguran√ßa. Ao manter-se atualizado, voc√™ garante que seus mecanismos de escalonamento autom√°tico estejam otimizados para efici√™ncia e seguran√ßa, mitigando poss√≠veis vulnerabilidades. Compatibilidade: Manter o KEDA atualizado garante compatibilidade com outros componentes em seu ecossistema nativo da nuvem, prevenindo problemas de integra√ß√£o.                                                                                                               |
| **Use R√≥tulos e Anota√ß√µes de Forma Inteligente**  | Categorize Eficientemente: R√≥tulos e anota√ß√µes s√£o pares chave/valor associados a objetos do Kubernetes, servindo como ferramentas flex√≠veis para categorizar, filtrar e gerenciar recursos dentro do seu ambiente Kubernetes. Ao aplicar r√≥tulos estrategicamente, voc√™ pode agrupar recursos relacionados, como Pods ou Servi√ßos, com base em caracter√≠sticas como ambiente, vers√£o da aplica√ß√£o ou qualquer outro crit√©rio personalizado relevante para suas necessidades operacionais. Anota√ß√µes complementam os r√≥tulos fornecendo um meio de anexar metadados n√£o identific√°veis aos seus recursos. |
| **Engajamento e Suporte da Comunidade**           | Mantenha-se Conectado: A comunidade KEDA √© dedicada ao avan√ßo e uso eficaz do Kubernetes Event-Driven Autoscaling. Ao participar dessa comunidade, voc√™ pode acessar conhecimento e suporte de colegas que enfrentaram desafios semelhantes. Esse engajamento pode assumir v√°rias formas, incluindo f√≥runs de discuss√£o, chamadas comunit√°rias, contribui√ß√£o ou revis√£o de documenta√ß√£o e participa√ß√£o em encontros online ou presenciais.                                                                                                                                                                |

## Primeiro laborat√≥rio: configurando o ambiente

Vamos configurar o ambiente de laborat√≥rio com as seguintes ferramentas:

- **Docker**: Usado pelo kind para provisionar o cluster Kubernetes.
- **kind**: Usado para criar clusters Kubernetes.
- **kubectl**: Usado para gerenciar o cluster Kubernetes.
- **Helm**: Usado para gerenciamento de pacotes Kubernetes.
- **Siege**: Uma ferramenta de teste de carga.

#### Configura√ß√£o do Ambiente Linux

Usaremos um host Ubuntu 22.04 e um cluster Kubernetes configurado usando kind.

Para configurar o Docker, siga estas etapas:

1. **Instale o Docker:**

   ```sh
   curl -fsSL https://get.docker.com/ | sh

   ```

2. **Habilite o Docker para iniciar na inicializa√ß√£o:**

   ```sh
   sudo systemctl enable --now docker
   ```

3. **Verifique se o servi√ßo Docker est√° em execu√ß√£o:**

   ```sh
   sudo systemctl status docker
   ```

4. **Adicione o usu√°rio atual ao grupo Docker:**

   ```sh
   sudo usermod -aG docker $USER
   ```

5. **Atualize a sess√£o do shell (saindo e entrando novamente).**

6. **Verifique a instala√ß√£o do Docker:**
   ```sh
   docker ps
   ```

Para instalar a vers√£o mais recente do kubectl, execute os comandos abaixo:

1. **Baixe o bin√°rio:**

   ```sh
   curl -sSL -O "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
   ```

2. **Modifique as permiss√µes:**

   ```sh
   chmod +x kubectl
   ```

3. **Mova para `/usr/local/bin`:**
   ```sh
   sudo mv kubectl /usr/local/bin
   ```

Para instalar a vers√£o mais recente do Helm, execute as seguintes etapas:

1. **Fa√ßa a instala√ß√£o do Helm:**
   ```sh
   curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
   chmod 700 get_helm.sh
   ./get_helm.sh
   ```

Para instalar a vers√£o mais recente do Siege, execute o seguinte comando:

1. **Instale o bin√°rio:**
   ```sh
   sudo apt-get install siege
   ```

O Siege √© uma ferramenta de teste de carga HTTP/FTP com m√∫ltiplas threads e utilit√°rio de benchmarking.

Para instalar o kind, execute o seguinte comando:

1. **Para AMD64/x86_64:**

   ```sh
   [ $(uname -m) = x86_64 ] && curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.24.0/kind-linux-amd64
   ```

2. **Modifique as permiss√µes:**

   ```sh
   chmod +x ./kind
   ```

3. **Mova o bin√°rio do kind para `/usr/local/bin`:**

   ```sh
   sudo mv ./kind /usr/local/bin/kind
   ```

4. **Crie o cluster:**

   ```sh
   kind create cluster
   ```

   Sa√≠da esperada:

   ```plaintext
   Creating cluster "kind" ...
   ‚úì Ensuring node image (kindest/node:v1.27.3) üñº
   ‚úì Preparing nodes üì¶
   ‚úì Writing configuration üìú
   ‚úì Starting control-plane üïπÔ∏è
   ‚úì Installing CNI üîå
   ‚úì Installing StorageClass üíæ
   Set kubectl context to "kind-kind"
   You can now use your cluster with:
   kubectl cluster-info --context kind-kind
   ```

5. **Verifique o cluster:**

   ```sh
   kubectl get ns
   ```

   Sa√≠da esperada:

   ```plaintext
   NAME                 STATUS   AGE
   default              Active   36s
   kube-node-lease      Active   36s
   kube-public          Active   36s
   kube-system          Active   36s
   local-path-storage   Active   30s
   ```

### Configura√ß√£o do Metric Server no Kubernetes

Para instalar o metric server no Kubernetes, execute os comandos abaixo:

1. **Adicione o reposit√≥rio Helm:**

   ```sh
   helm repo add metrics-server https://kubernetes-sigs.github.io/metrics-server/
   ```

2. **Instale o metric server:**

   ```sh
   helm upgrade --install metrics-server metrics-server/metrics-server -n kube-system --set "args[0]=--kubelet-insecure-tls"
   ```

3. Verifique a instala√ß√£o:
   ```
   kubectl get pods -n kube-system -l=app.kubernetes.io/name=metrics-server
   ```

Agora o nosso ambiente est√° pronto!

## Segundo laborat√≥rio: implementando o HPA no Kubernetes

### Pr√©-requisitos

Cluster Kubernetes com o metric server instalado conforme o Lab 1.

### Exerc√≠cio 2.1: Implantar Aplica√ß√£o de Exemplo no Kubernetes

Neste primeiro exerc√≠cio, vamos implantar uma aplica√ß√£o de exemplo no Kubernetes. Esta aplica√ß√£o ser√° usada para demonstrar as estrat√©gias de autoscaling do HPA dispon√≠veis no Kubernetes.

1. **Crie o arquivo `webapp.yaml` com o conte√∫do abaixo. Este arquivo define uma implanta√ß√£o Kubernetes para sua aplica√ß√£o de exemplo:**

   ```yaml
   apiVersion: apps/v1
   kind: Deployment
   metadata:
     name: webapp
   spec:
     replicas: 2
     selector:
       matchLabels:
         app: webapp
     template:
       metadata:
         labels:
           app: webapp
       spec:
         containers:
           - image: nginx
             name: nginx
             resources:
               limits:
                 cpu: '10m'
               requests:
                 cpu: '10m'
   ```

2. **Implante a aplica√ß√£o:**

   ```sh
   kubectl apply -f webapp.yaml
   ```

3. **Verifique a implanta√ß√£o:**

   ```sh
   kubectl get deployments
   ```

   Sa√≠da esperada:

   ```plaintext
   NAME    READY   UP-TO-DATE   AVAILABLE   AGE
   webapp  2/2     2            2           89s
   ```

4. **Configure o port forwarding para acessar a aplica√ß√£o.**

   Neste passo, estamos estabelecendo uma regra de port forwarding que redireciona o tr√°fego de rede de uma porta espec√≠fica em sua m√°quina local para a porta correspondente no pod Kubernetes que hospeda o servidor. Ao fazer isso, voc√™ habilita o acesso direto ao servidor via `http://localhost:8080` a partir do seu computador local. Esta a√ß√£o conecta o ambiente local ao pod Kubernetes isolado, permitindo que voc√™ teste e interaja com a aplica√ß√£o implantada como se ela estivesse sendo executada localmente. √â importante executar isso em uma nova aba do terminal para manter o port forwarding ativo durante toda a sess√£o de teste.

   ```sh
   kubectl port-forward deploy/webapp 8080:80
   ```

   Sa√≠da esperada:

   ```plaintext
   Forwarding from 127.0.0.1:8080 -> 80
   Forwarding from [::1]:8080 -> 80
   ```

5. **Teste a aplica√ß√£o de exemplo enviando uma solicita√ß√£o HTTP:**

   ```sh
   curl http://localhost:8080/
   ```

   Sa√≠da esperada:

   ```html
   <!DOCTYPE html>
   <html>
     <head>
       <title>Welcome to nginx!</title>
       <style>
         html {
           color-scheme: light dark;
         }
       </style>
     </head>
     <body>
       <h1>Welcome to nginx!</h1>
     </body>
   </html>
   ```

### Exerc√≠cio 2.2: Configurar e Testar o HPA

Neste exerc√≠cio, vamos configurar o Horizontal Pod Autoscaler no Kubernetes.

1. **Crie um recurso HPA.**

   Este recurso ir√° escalar automaticamente sua implanta√ß√£o com base na utiliza√ß√£o da CPU. Vamos come√ßar criando um Horizontal Pod Autoscaler para nossa implanta√ß√£o Kubernetes usando o comando `kubectl autoscale`:

   ```sh
   kubectl autoscale deployment webapp --min=2 --max=5 --cpu-percent=20
   ```

   Sa√≠da esperada:

   ```plaintext
   horizontalpodautoscaler.autoscaling/webapp autoscaled
   ```

2. **Verifique se o HPA foi implantado corretamente:**

   ```sh
   kubectl get hpa
   ```

   Sa√≠da esperada:

   ```plaintext
   NAME    REFERENCE          TARGETS   MINPODS   MAXPODS   REPLICAS   AGE
   webapp  Deployment/webapp  0%/20%    2         5         2          23s
   ```

3. **Gere carga usando o Siege.**

   Neste passo, estamos usando a ferramenta Siege para gerar tr√°fego para nossa aplica√ß√£o. √Ä medida que o uso da CPU ultrapassa os limites definidos, o HPA responde automaticamente acionando seu mecanismo de escalonamento. O HPA aumenta o n√∫mero de r√©plicas de pods para lidar com a carga aumentada. Este escalonamento garante que a aplica√ß√£o mantenha seu desempenho e capacidade de resposta, apesar da demanda aumentada.

   ```sh
   siege -q -c 2 -t 1m http://localhost:8080
   ```

4. **Monitore o autoscaling.**

   Neste passo, estamos monitorando ativamente o comportamento do Horizontal Pod Autoscaler enquanto ele responde √† carga aumentada. Executando `kubectl get hpa`, voc√™ pode observar a resposta em tempo real do HPA √† mudan√ßa na utiliza√ß√£o da CPU. Este comando exibe m√©tricas cruciais, como o uso atual da CPU, o uso alvo (definido em 20% em nossa configura√ß√£o) e o n√∫mero atual de r√©plicas.

   O HPA opera monitorando continuamente m√©tricas especificadas - neste caso, a utiliza√ß√£o da CPU - e ajustando o n√∫mero de r√©plicas de pods para atender √† utiliza√ß√£o alvo desejada. Quando a carga aumenta e o uso da CPU ultrapassa o limite de 20%, o HPA responde escalando o n√∫mero de pods.

   ```sh
   kubectl get hpa -w
   ```

   Sa√≠da esperada:

   ```plaintext
   NAME    REFERENCE          TARGETS   MINPODS   MAXPODS   REPLICAS   AGE
   webapp  Deployment/webapp  20%/20%   2         5         3          85s
   ```

   A sa√≠da acima mostra que o HPA escalou a implanta√ß√£o `webapp` para 3 r√©plicas. Esta a√ß√£o de escalonamento √© uma resposta direta ao aumento da utiliza√ß√£o da CPU, que ultrapassou o limite definido de 20%. Os aspectos importantes a serem observados aqui s√£o os seguintes:
   - **TARGETS**: Indica a utiliza√ß√£o atual/m√©dia da CPU (20%) em rela√ß√£o ao alvo definido (20%). A correspond√™ncia aqui acionou o escalonamento.
   - **MINPODS e MAXPODS**: Representam o n√∫mero m√≠nimo (2) e m√°ximo (5) de pods que o HPA pode escalar. Neste caso, o n√∫mero de r√©plicas aumentou, mas ainda est√° dentro dos limites definidos.
   - **REPLICAS**: Mostra a contagem atual de r√©plicas (3), que aumentou a partir da contagem original para lidar com a carga maior.

5. **Limpeza do HPA, delete o HPA e a implanta√ß√£o:**

   ```sh
   kubectl delete hpa webapp
   kubectl delete deploy webapp
   ```

## Terceiro laborat√≥rio: instalando o KEDA e Configurando o Cron Scaler

### Pr√©-requisitos

Cluster Kubernetes com o servidor de m√©tricas instalado conforme o laborat√≥rio 1.

### Exerc√≠cio 3.1: Instalar o KEDA Usando o Helm Chart

Neste exerc√≠cio, vamos instalar o KEDA usando um Helm chart.

1. **Instale o KEDA usando o Helm.** Execute os seguintes comandos para come√ßar:
   ```sh
   helm repo add kedacore https://kedacore.github.io/charts
   helm repo update
   helm upgrade -i keda kedacore/keda --namespace keda --create-namespace
   ```

````markdown
## Terceiro laborat√≥rio: instalando o KEDA e Configurando o Cron Scaler

Este laborat√≥rio fornece experi√™ncia pr√°tica na instala√ß√£o do KEDA em um ambiente Kubernetes. Faremos uso do Cron ScaledObject para dimensionar a aplica√ß√£o com base em um cronograma de tempo.

### Pr√©-requisitos

Cluster Kubernetes com o servidor de m√©tricas instalado conforme o Laborat√≥rio 1.

### Exerc√≠cio 3.1: Instalar o KEDA Usando o Helm Chart

Neste exerc√≠cio, vamos instalar o KEDA usando um Helm chart.

1. **Instale o KEDA usando o Helm.** Execute os seguintes comandos para come√ßar:
   ```sh
   helm repo add kedacore https://kedacore.github.io/charts
   helm repo update
   helm upgrade -i keda kedacore/keda --namespace keda --create-namespace
   ```
````

2. **Verifique se os pods do KEDA est√£o em execu√ß√£o no cluster, usando o comando abaixo:**

   ```sh
   kubectl get deployment -n keda
   ```

3. **Crie uma implanta√ß√£o usando o comando abaixo:**

   ```sh
   kubectl create deploy myapp --image nginx --replicas=2
   ```

4. **Verifique a implanta√ß√£o:**

   ```sh
   kubectl get deployments
   ```

5. **Crie um arquivo `cron.yaml` com o conte√∫do abaixo. Este arquivo define um Kubernetes ScaledObject para sua aplica√ß√£o de amostra:**

   ```yaml
   apiVersion: keda.sh/v1alpha1
   kind: ScaledObject
   metadata:
     name: cron-scaledobject
     namespace: default
   spec:
     scaleTargetRef:
       name: myapp
     triggers:
       - type: cron
         metadata:
           timezone: Asia/Kolkata
           start: 30 * * * *
           end: 45 * * * *
           desiredReplicas: '10'
   ```

6. **Crie o ScaledObject usando o comando abaixo:**

   ```sh
   kubectl apply -f cron.yaml
   ```

7. **Verifique o ScaledObject:**

   ```sh
   kubectl get scaledobject.keda.sh
   ```

8. **O ScaledObject dimensionar√° os pods da aplica√ß√£o para o n√∫mero desejado de r√©plicas quando o cronograma for acionado.**
   ```sh
   watch kubectl get all
   ```

O dimensionador Cron permite que voc√™ defina um intervalo de tempo no qual deseja dimensionar suas cargas de trabalho para cima e para baixo. Quando a janela de tempo come√ßar, ele dimensionar√° do n√∫mero m√≠nimo de r√©plicas para o n√∫mero desejado de r√©plicas com base em sua configura√ß√£o. Neste exerc√≠cio de laborat√≥rio, fizemos uso de um dimensionador Cron simples, que dimensiona as aplica√ß√µes com base em um cronograma espec√≠fico. Voc√™ pode explorar ainda mais os diferentes dimensionadores dispon√≠veis.

---

Este artigo foi traduzido e adaptado do curso gratuito da Linux Foundation [Scaling Cloud Native Applications with KEDA](https://training.linuxfoundation.org/express-learning/scaling-cloud-native-applications-with-keda-lfel1014/).

### Fontes Utilizadas:

- [Documenta√ß√£o Oficial do KEDA](https://keda.sh/docs/latest/)
- [Reposit√≥rio GitHub do KEDA](https://github.com/kedacore/keda)
- [Curso da Linux Foundation: Scaling Cloud Native Applications with KEDA](https://training.linuxfoundation.org/express-learning/scaling-cloud-native-applications-with-keda-lfel1014/)

```
---

Este artigo foi traduzido e adaptado do curso gratuito da Linux Foundation [Scaling Cloud Native Applications with KEDA](https://training.linuxfoundation.org/express-learning/scaling-cloud-native-applications-with-keda-lfel1014/).

### Fontes Utilizadas:
- [Documenta√ß√£o Oficial do KEDA](https://keda.sh/docs/latest/)
- [Reposit√≥rio GitHub do KEDA](https://github.com/kedacore/keda)
- [Curso da Linux Foundation: Scaling Cloud Native Applications with KEDA](https://training.linuxfoundation.org/express-learning/scaling-cloud-native-applications-with-keda-lfel1014/)
```
